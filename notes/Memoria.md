---
layout: page
permalink: notes/memoria
tags: italian
title: Memoria
---

Ripasso Prox: 40
Ultima modifica: March 30, 2023 3:39 PM
Primo Abbozzo: September 21, 2021 7:10 PM
Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—
Studi Personali: No

# Elementi da ripassare

- Vecchi dubbi
    - Principio di localitÃ  e temporalitÃ 
- Le tipologie di raid
- November 29, 2021 9:22 PM

# 4 Memoria

## 4.1 Caratteristiche della Memoria

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled.png" alt="image/universita/ex-notion/Memoria/Untitled">

La gerarchia della memoria, piÃ¹ si va giÃ¹ piÃ¹ spazio si ha, piÃ¹ Ã¨ lento il caricamento delle informazioni

### 4.1.1 Catalogazione della memoria

Le tipologie di memoria sono presenti a fianco.

In generale piÃ¹ la memoria Ã¨ veloce da riprendere, piÃ¹ Ã¨ costosa da memorizzare (c'Ã¨ poco spazio)

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 1.png" alt="image/universita/ex-notion/Memoria/Untitled 1">

### 4.1.2 Byte e Word

Il libro a pagina 74 parte con la discussione del perchÃ© si Ã¨ preferito **evitare la BCD** (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.

La memoria Ã¨, in modo spiccio, **una serie di cellette numerate**, ognuno puÃ² contenere qualche informazione.

Nacque nel 1960 circa con IBM 360 nacque la definizione di **byte**.

**Word** Ã¨ una seguenza di byte â†’ unitÃ  di dato che non stanno solamente in un singolo indirizzo.

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 2.png" alt="image/universita/ex-notion/Memoria/Untitled 2">

### 4.1.3 Endianess

Questi termini descrivono l'organizzazione dei bytes all'interno della memoria. A volte Ã¨ molto conveniente netere i bytes al contrario per facilitÃ  di accesso.

### 4.1.4 RAM

Abbiamo presentato il funzionamento hardware della RAM nel momento in cui abbiamo descritto il funzionamento di [Circuiti Sequenziali](/notes/circuiti-sequenziali) come LATCH SR, D, DFF.

### 4.1.5 Paginazione - Caricamento

Una altra funzione della gerarchia di memoria Ã¨ utilizzare la paginazione, ossia il caricamento di risorse utili nella ram veloce e scaricamento nella memoria secondaria di ciÃ² che non viene utilizzato.

Ãˆ gestito dal sistema operativo.

Sono dei blocchi di data nella memoria principale che vengono caricati nella memoria principale nel momento del bisogno.

Quindi ci sono proprio degli **algoritmi per caricare e scaricare** le pagine di memoria dalla memoria principale, gestiti dal sistema operativo.

## 4.2 Memoria Cache

La cache Ã¨ una zona di memoria condivisa alle CPU, di facile accesso (meno facile in confronto ai registri, ma comunque veloce) ma senza molto spazio.

Ãˆ *sempre consultata* ** prima di andare nella memoria.

Se va a cercare un word in memoria, questa viene messa nella cache dopo essere ritrovata.

Una caratteristica principale della cache Ã¨ che non Ã¨ necessario al programmatore sapere che esiste o meno, Ã¨ solo **qualcosa che si interpone in modo TRASPARENTE** che puÃ² rispondere subito nel caso possieda una certa informazione.

Ma lâ€™idea di tenere una memoria piÃ¹ veloce intermedia per dati piÃ¹ utili del prossimo futuro Ã¨ una idea che si utilizza anche in altri ambiti (come Disco, accesso messaggi, e simili) e **migliora molto la velocitÃ **.

### 4.2.1 Livelli memoria Cache

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 3.png" alt="image/universita/ex-notion/Memoria/Untitled 3">

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 4.png" alt="image/universita/ex-notion/Memoria/Untitled 4">

### 4.2.2 Principio di l**ocalitÃ  spaziale e temporale**

> Programmi eseguiti vicini nel tempo sono messi in luoghi in memoria vicini
>

Si spera di guadagnare tempo in questo modo, cosÃ¬ Ã¨ piÃ¹ facile ritrovare delle informazioni utili quando si eseguono dei comandi vicini nella cache.

Chiaramente se un programma continua a saltare da un indirizzo della memoria a un altro questo principio non ha piÃ¹ senso e la cache servirebbe a poco.

**LocalitÃ  spaziale e temporale**

Un programma naturale di solito utilizza la cache (un programma potrebbe essere progettato in modo che usi 0 cache, ma sarebbe uno spreco di risorse).

**Temporale:** la stessa cella viene acceduta a breve distanza di tempo (come Stack)

**Spaziale:** celle vicine possono essere prese a breve tempo di distanza. (per esempio accedere ad un array, accesso sequenziale che ha un nome suo di localitÃ  sequenziale)

Ãˆ molto facile che la cache debba accedere alla stessa risorsa in termini brevi di tempo

**LocalitÃ  secondo [WIKI](https://en.wikipedia.org/wiki/Locality_of_reference)**

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 5.png" alt="image/universita/ex-notion/Memoria/Untitled 5">

### 4.2.3 Efficienza della cache

La velocitÃ  d'accesso alla cache Ã¨ di granlunga minore rispetto a quello della memoria, di solito il tempo speso per memorizzare qualcosa qui viene sempre recuperato.

Usiamo un pÃ² di matematica ora per descrivere questa cosa un pochino piÃ¹ rigorosamente:

$$c << m$$ con $$c$$ il tempo per accedere alla cache e $$m$$ il tempo per accedere alla memoria.

Allora si ha che il tempo medio per accedere alle informazioni, tenendo $$h$$ come *hit rate* Ã¨ di:


$$
hc + (1 - h)(c + m) = c + (1-h)m
$$


### 4.2.4 Cache ad accesso diretto

Linee di cache, vanno k mod n, ogni linea di cache di dimensione m. ok? Ãˆ una cosa temporale, a seconda di cosa ci sia ora.

Data: Ã¨ effettivamente il data che sto prendendo

n Ã¨ il numero di linee di cache (che decide quanto grande sia la cache).

Tag serve per sapere quale blocco sto utilizzando (quindi se 0-31 oppure 65536 e simili)

Valid se Ã¨ un blocco valido, se Ã¨ 0 vuol dire che non Ã¨ roba interessante.

- Esempio di query cache

    Teniamo 5 bit per l'indicizzazione dentro i 32 bit di data.

    11 bit per sapere quale linea di cache utilizzare

    16 bit per confrontare con il tag e vedere se Ã¨ giusto oppure no.

    CosÃ¬ riesco a trovare in modo univoco la linea di cache che mi serve.


<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 6.png" alt="image/universita/ex-notion/Memoria/Untitled 6">

### 4.2.5 Cache hit and miss

Si dice che si ha un cache hit oppure cache miss a seconda del caso in cui la cache Ã¨ riuscita a dare la richiesta oppure meno.

**Miss**

1. **Riportare la cache in memoria centrale** in quanto potrebbe essere modificata ora, Ã¨ un aggiornamento della roba nella memoria centrale
2. **Caricare la nuova memoria**.

Se perÃ² si tenta di accedere alla cache allo stesso momento, si possono esserci **data race** e quindi bisognerebbe bloccare l'accesso all'inizio

Se vuoi approfondire su algoritmi per la gestione della cache:

[https://en.wikipedia.org/wiki/Cache-oblivious_algorithm](https://en.wikipedia.org/wiki/Cache-oblivious_algorithm)

e altro ancora

## 4.3 Memoria secondaria

Storicamente le velocitÃ  delle CPU si sono sviluppate molto piÃ¹ velocemente rispetto alle memorie secondarie.

### 4.3.1 Hard Disk (4)

I dischi magnetici oppure **Hard disk** sono generalmente in tre parti:

- **Settore** Ã¨ il nome di una traccia specifica di memoria di dimensione fissata.
- **Traccia** Ã¨ una sequenza di bit circolari
- **Testina** che magnetizza e modifica il contenuto nel disco.
- **Controllore Disco** .

Ogni settore comincia con un preamble che dovrebbe aiutare a diminuire gli errori di lettura.

Per dare un senso, circa in un centimetro di Hard Disk ci possono stare parecchi giga di informazioni.

I dati posso essere messi in due modi:

- Stessa densitÃ  per angolo (piÃ¹ rientri piÃ¹ hai i dati in modo compatto)
- Diverso numero di settori (la parte esterna del disco contiene piÃ¹ settori)

**Processo di recupero di dati:**

1. La CPU dice di andare a recuperare un blocco in un certo indirizzo di memoria
2. La testina gira e va fisicamente a recuperare la zona di memoria

### 4.3.2 SSD

**SSD** or Solid State drive non hanno nessuna parte che si muove quindi sono meno soliti a rompersi meccanicamente, *tutto elettronico*.

Storicamente sono state utilizzate per portatili per resistenza ad urti, ma poi si possono utilizzare anche per altro data la loro velocitÃ  (per minore spazio).

## 4.4 **RAID**

[https://en.wikipedia.org/wiki/Standard_RAID_levels](https://en.wikipedia.org/wiki/Standard_RAID_levels)

Redundant array of indipendend disks (originariamente inexpensive, per contrapporla a Single Large Expensive Disk ossia SLED, ma poi hanno scoperto che anche RAID costa, LMAO.

### 4.4.1 Vantaggi generali

Redundant Array of Inexpensive Disks.

- Ridurre il gap di efficienza fra CPU e HD
- Utilizzo di piÃ¹ dischi in contemporanea + lettura di dati
- FacilitÃ  di correttezza di dati e verifica errori

### 4.4.2 6 Tipologie di RAID

Diminuire di 1 l'intera lista, perchÃ© RAID va da 0

Non redundant data striping (C'Ã¨ solo una copia di dati nel disco) **VelocitÃ **, no info retrieval

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 7.png" alt="image/universita/ex-notion/Memoria/Untitled 7">

Redundant, c'Ã¨ una copia esatta dei RAID e sono **entrambi striped**

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 8.png" alt="image/universita/ex-notion/Memoria/Untitled 8">

C'Ã¨ bisogno di una grande sincronizzazione in quanto i dati sono divisi fra i dischi a livello bit.

1. Possono avere solamente una richiesta, a differenza di RAID 1 che puÃ² gestirne tanti

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 9.png" alt="image/universita/ex-notion/Memoria/Untitled 9">

Unico raid mai utilizzato, perÃ² introduce Hamming per la corrrezione!

Uguale al terzo ma c'Ã¨ un bit di paritÃ  per controllo errori invece che codice hamming, spesso bit di paritÃ  Ã¨ bastato.

1. Solo una richiesta

https//en.wikipedia.org/wiki/Parity_bitÂ disk with each color representing the group of blocks in the respectiveÂ [parity](https://en.wikipedia.org/wiki/Parity_bit)Â block (a stripe)](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2010.png)

A RAIDÂ 4 setup with dedicatedÂ [parity](https://en.wikipedia.org/wiki/Parity_bit)Â disk with each color representing the group of blocks in the respectiveÂ [parity](https://en.wikipedia.org/wiki/Parity_bit)Â block (a stripe)

Ritornano gli stripe, ma stavolta un intero disco Ã¨ utilizzato per verificare che la scrittura Ã¨ stata corretta,

1. Ã¨ brutto se vogliamo scriverci

![Anche questo utilizzato poco
Diagram of a RAIDÂ 3 setup of six-byte blocks and twoÂ [parity](https://en.wikipedia.org/wiki/Parity_bit)Â bytes, shown are two blocks of data in different colors.](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2011.png)

Anche questo utilizzato poco
Diagram of a RAIDÂ 3 setup of six-byte blocks and twoÂ [parity](https://en.wikipedia.org/wiki/Parity_bit)Â bytes, shown are two blocks of data in different colors.

Risolve una lentezza del punto 5 distribuendo le sezioni di controllo sui vari dischi.

https//en.wikipedia.org/wiki/Parity_bitÂ block (a stripe). This diagram showsÂ *Left Asynchronous*Â layout](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2012.png)

RAIDÂ 5 layout with each color representing the group of data blocks and associatedÂ [parity](https://en.wikipedia.org/wiki/Parity_bit)Â block (a stripe). This diagram showsÂ *Left Asynchronous*Â layout

Non so quale sia la differenza con il 5, per saperlo vai a leggere i raid su [Devices OS](/notes/devices-os). In pratica fault tolerance maggiore.

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 13.png" alt="image/universita/ex-notion/Memoria/Untitled 13">

## 4.5 Errori

Controllare come sono causati gli errori
E tipologie di errori

Questa parte Ã¨ scritta molto meglio in [Rappresentazione delle informazioni](/notes/rappresentazione-delle-informazioni)

dove si parla di hamming distance e correzione errori.

### 4.5.1 Cause degli errori

Gli errori possono essere causati da:

- Raggi cosmici provenienti dal sole
- Vibrazioni fisiche

### 4.5.2 Hamming Distance

## 4.6 Altri dispositivi

### 4.6.1 Dischi ottici

Un laser va a leggere i pattern di Pit-land e Land-pit, pit-pit presenti sul compact disk.

I dischi sono sostanzialmente uguali per quanto riguarda l'encoding di 1 e 0 ma sono diversi per quanto riguarda *il materiale impiegato*, il raggio impiegato **lo spazio presente fra le varie linee di informazioni (la compattezza dei bit) e simili.

<img src="/images/notes/image/universita/ex-notion/Memoria/Untitled 14.png" alt="image/universita/ex-notion/Memoria/Untitled 14">

### 4.6.2 Output-Input

Per gestire tutti i pixel c'Ã¨ la necessitÃ  di avere architetture molto complicate, circa devono fare update di milioni di pixel in decimi di secondo (altrimenti l'occhio capisce che c'Ã¨ la distanza)

- Core complessi per la gestione di di milioni di Pixel.
- Linguaggi di programmazione specifici perchÃ© piÃ¹ efficienti della CPU per programmi non grafici e.g. Cuda-C.

### 4.6.3 Bus per dispositivi

sono legati tramite BUS, collegamenti elettrici.

- BUS di dati
- BUS di indirizzi

I bus trasportano piccole quantitÃ  di informazioni. Si possono dividere in **sotto-bus.**

I bus si sono evoluti nel tempo, partendo da standard ISA (industry standard architetture) sono state creati moderni bus molto piÃ¹ veloci PCI, PCIe e simili.

**Collegamento con memoria e CPU**

- Controller collega gli attacchi ai dispositivi ai Bus che si collegano all'unitÃ  di controllo. (la scrittura sul bus Ã¨ controllata dalla CPU)
- Altri dispositivi parlano direttamente alla memoria **DMA** mandano e ricevono degli interrupt. (se non usasse interrupt altra soluzione sarebbe continuamente inviare delle richieste per chiedere se sta ancora andando o meno)

**Direct Memory Access**

Di questo ne parliamo un pÃ² meglio, anche se alla fine Ã¨ lo stesso concetto in [Note sullâ€™architettura](/notes/note-sullâ€™architettura)

Per saperne di piÃ¹ su interrupt e trap

Sarebbe molto inefficiente leggere e inviare continuamente, quindi mettiamo un trasferimento RAM â†’ Disco senza passare dalla CPU. Quando finisce il trasferimento il dispositivo invia un **Interrupt** che viene gestito subito dalla CPU interrompendo il processo corrente, iniziando un **interrupt handler** che gestisca eventuali errori del dispositivo e informa il sistema operativo che Ã¨ finito il processo di I/O.
l processo corrente, iniziando un **interrupt handler** che gestisca eventuali errori del dispositivo e informa il sistema operativo che Ã¨ finito il processo di I/O.

# References