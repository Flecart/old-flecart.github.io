---
layout: page
permalink: notes/note-sullâ€™architettura
tags: italian
title: Note sullâ€™architettura
---

Ripasso Prox: 30
Ripasso: June 1, 2023
Ultima modifica: April 16, 2023 12:33 PM
Primo Abbozzo: February 23, 2023 5:13 PM
Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•
Studi Personali: No

# Elementi di ripasso

- Chiedi chiarimenti sul perchÃ©  Ã¨ necessario avere stack separati per la gestione di interrupt multipli annidati. Non basterebbe aggiungere sulla stack che ho giÃ ? Poi quando finisco lâ€™interrupt elimino quanto mi ha aggiunto lâ€™ultimo interrupt, e la roba vecchia câ€™Ã¨ ancora.

# Note sullâ€™architettura

## Interrupt

### Descrizione iniziale ðŸŸ©

Di interrupt e trap se nâ€™Ã¨ parlato un pÃ² in [Livello ISA](/notes/livello-isa) di architettura, ora andiamo ad approfondire come viene gestito a livello SO.

Un interrupt Ã¨ un **segnale** che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato **trap** che Ã¨ un interrupt software sincrono..

- Slide Interrupt Hardware e software

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled">


Questi segnali sono utilizzati per **indicare eventi** che dovrebbero essere gestiti (come end of I/O, divisione per 0, ma anche semplicemente syscall e passare livello kernel).

Il segnale solitamente implica la interruzione di quanto viene svolto in questo momento, per gestire lâ€™interrupt corrente, e poi tornare allâ€™istruzione precedente. Solitamente perchÃ© potrebbe anche essere che il processo non sia interrompibile, e quindi lâ€™interrupt dovrebbe essere rischedulato.

Per poter ripristinare lo stato precedente solitamente ci si devono salvare lâ€™immagine dei registri del programma, tutte le informazioni utili a far runnare il processo (di solito messe nelle PCB), e lâ€™istruzione di ritorno.

Quando ci si ritorna sopra basta mettere nel PC lâ€™indirizzo della istruzione corretta.

### Procedimento classico di gestione interrupt ðŸŸ©

Praticamente durante il Ciclo va a fare un check per vedere se il filo dellâ€™interrupt Ã¨ settato, se sÃ¬ carica istruzioni a un certo indirizzo (e si deve salvare lâ€™istruzione attuale).

Masked se si sta facendo qualcosa che non si puÃ² interrompere, quindi Ã¨ **delayed**. (quando il processore non puÃ² essere interrotto, ad esempio quando sei in [Sezioni Critiche](/notes/sezioni-critiche), o quando arrivano interrupt dello stesso tipo, se ogni interrupt ha una stack propria, andrebbe a sovrascrivere).

Se tutto va bene e non Ã¨ delayed ed esiste un interrupt, ad alto livello fa:

1. Sospende (in un modo che possa essere ripreso) il processo corrente
2. Salta allâ€™istruzione definito in **interrupt vector** **(**tabella fissa cosÃ¬ Ã¨ piÃ¹ veloce)
3. Esegue lâ€™interrupt
4. Si ritorna al processo precedente, o altro (scheduling potrebbe far andare in altro processo).

- Slides passi ad alto livello

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 1.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 1">

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 2.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 2">

- Slides passi a basso livello (!!!)

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 3.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 3">

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 4.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 4">

    Fino a qui **tutte le operazioni sono HARDWARE**. Da ora in poi viene ripreso il ciclo FDE con il controllo dell Interrupt handler.

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 5.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 5">


### Tipologie di gestione di interrupt Multipli (2) ðŸŸ©

Quando ho interrupt multipli diventa leggermente piÃ¹ difficile gestire questi interrupt. Potrebbero interagire, che succede quando mi arriva un interrupt da device 1 mentre sto runnando lâ€™interrupt handler di device 2???

**Disabilitazione degli interrupt**

Questa Ã¨ la forma piÃ¹ semplice per la gestione dellâ€™interrupt, in pratica quando sto gestendo un interrupt, li disabilito, in modo che non possa riceverne altri, cosÃ¬ sono sicuro che non posso ricevere nessun altro interrupt. Una soluzione simile per le CS ne abbiamo discusso in [Sezioni Critiche](/notes/sezioni-critiche)

Quando sto per finire riattivo gli interrupt e cosÃ¬ posso vedere se ce ne erano alcuni pendenti.

Ho alcuni svantaggi come:

1. Non ho un concetto di prioritÃ  degli interrupt a questo livello
- Slide idea di gestione

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 6.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 6">


**Annidamento degli interrupt**

Questa Ã¨ la soluzione piÃ¹ moderna, ed Ã¨ anche la piÃ¹ efficiente che permette di

1. Avere un concetto di prioritÃ  di interrupts
2. Necessita di stack separati (se gli interrupt utilizzano la stessa stack, potrebbero sovrascriversi alcune informazioni!) quindi piÃ¹ difficile da implementare.
    1. Forse ogni interrupt ha una propria stack, se viene stetsso tipo di interrupt sono maskerati!

### PI/O, or Interrupt based I/O ðŸŸ©

**PI/O**

In questo caso la CPU setta tutti i valori utili al controllore del device driver. e poi fa **polling** per chiedere al driver se ha finito o meno (attraverso un controllo sul registro di stato del driver).

Se il driver ha finito, la CPU si mette a copiare i dati di output del device alla propria memoria.

Un chiaro svantaggio Ã¨ che il polling Ã¨ molto inefficiente per la soluzione di questo tipo di problemi.

**Interrupt driven I/O**

Questa Ã¨ la soluzione moderna, quella piÃ¹ utilizzata, dato che ora Ã¨ il dispositivo driver a comunicare quando un processo I/O Ã¨ stato completato o men, cosÃ¬ la CPU Ã¨ a conoscenza di questo evento e puÃ² comportarsi di conseguenza. (quindi quando gestire lâ€™interrupt, e poi effettivamente runnare il codice corrispondente quando lâ€™interrupt Ã¨ avvenuto).

## Memoria

### Direct Memory Access ðŸŸ©

Per copiare alcuni dati utili per I/O dalla memoria RAM alla memoria del controllore bisognerebbe spendere tanti cicli di clock della CPU, di solito questa Ã¨ una operazione molto lenta.

DMA ci permette di accedere direttamente alla memoria, quindi il controllore stesso Ã¨ programmato con lâ€™indirizzo su cui andare a prelevare la memoria corretta, sollevando la CPU da questo primo lavoro.

Chiaramente il vantaggio principale di questo metodo Ã¨ la velocitÃ , dato che abbiamo piÃ¹ cicli di clock per la CPU, oltre a questo, crea una interfaccia piÃ¹ facile da gestire, quindi i drivers sono piÃ¹ semplici.

Uno svantaggio Ã¨ la contesa del BUS, che per trasferire câ€™Ã¨ bisogno che il bus sia libero.

**Sicurezza**

Questo Ã¨ un possibile falla di sicurezza, infatti se il codice del controller Ã¨ malevolo potrebbe fare attacchi al sistema di certo tipo.

Secondo Renzo sarebbe meglio che questo codice fosse open, in modo che sia molto probabile di trovare cose maligne.

### Ram ðŸŸ©

Ãˆ semplificata da poche istruzioni di accesso, che di solito sono solo LOAD E STORE. (Tutti i dettagli fisici sono astratti, la CPU non si interessa di questi, sono built-in del calcolatore!).

Di solito (in modi che non so), sono gestiti da MMU.

NOTA: ci mettono un pÃ² i condensatori a scaricarsi. (possibile recuperare un pÃ² di informazioni se tipo congeli la RAM subito).

Le **ROM** esistono ancora, ma sono per cose basilari, come per la parte del boot.

### Memory Mapped I/O ðŸŸ©-

Alcune aree di memoria, come quelle del video grafico, sono scritti e letti subito da alcuni driver e sono utilizzati per sapere cosa mostrare sullo schermo per esempio.

Ma dato che 2 componenti (read and write) devono **sincronizzarci** nella lettura. Questa sincronizzazione di solito Ã¨ fatta a livello hardware.

### Dischi e SSD ðŸŸ©

Abbiamo spiegato meglio questa parte in [Devices OS](/notes/devices-os)

Dischi memorizzano in maniera magnetica, e lo fanno in maniera non-volatile, cioÃ¨ possiamo ritrovare i nostri dati.

Sono a accesso diretto, in contrasto con i nastri che erano sequenziali. leggermente accennato in [Memoria](/notes/memoria). E per capire dove leggere e scrivere si devono impostante movimenti di settore del cilindro e testina per leggere il settore corretto. Settore si aspetta che giri, testina si aspetta che si sposti. Ãˆ lento, nellâ€™ordine dei microsecondi.

**Operazioni possibili**

READ, WRITE e anche Seek (quando vado a spostare la testina da altre parti!)

- Slide

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 7.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 7">


**Osservazioni sulla velocitÃ **

Non ci converrebbe avere uno stesso file messo in posti molto diversi fra di loro allâ€™intenro del disco!

Cose di scheduling in modo da leggere cose che siano vicine. (Ma anche il filesystem, in modo che cose che cose che vengono utilizzate spesso siano vicine, ma questa roba la vedremo dopo)

**SSD, Solid State Disk**

Anche questi sono per cose non volatili.

Solitamente scrivono ad insieme di blocchi! e lo si fa in **cicli di scrittura** perchÃ© non scrive ad ogni singola scrittura, ma sono in un buffer, e saranno scritti insieme in tutti in un ciclo di scrittura, questo Ã¨ per rendere piÃ¹ efficiente questa operazione.

Per ssd a volte tengo la RAM come una cache intermedia per la scrittura.

### Gerarchie di memoria ðŸŸ©

- Slide piramide

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 8.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 8">

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 9.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 9">


Lâ€™altro argomento si parlerebbe di Cache, ma penso sia trattato giÃ  benissimo in 4.2 Memoria Cache

Quindi guardare lÃ¬, guardare la piramide della memoria il tradeoff velocitÃ  e quantitÃ  di memoria, il costo di accesso (in termini di tempo ed energia).

## Sicurezza

Il processo

- Non dovrebbe accedere ad aree di memoria a cui non dovrebbe accedere
- Non dovrebbe accedere direttamente ai dispositivi I/O, altrimenti potrei accedere e modificare qualunque cosa sui driver, e qualunque processo potrebbe farlo.

Ãˆ importante garantire la sicurezza anche per lâ€™**affidabilitÃ  del sistema**, anche per proteggere il programmatore stesso, quando fa qualcosa in modo accidentale, in modo da evitare danni brutti. al sistema

### Mode Bit ðŸŸ©

nella realtÃ  le protezioni principali sono due, messe a livello hardware

1. Un **Mode bit** che sta a specificare se il **CPU Ã¨ in Kernel mode o user mode**.
    1. Questi metodi sono importanti perchÃ© il modo kernel permette accesso totale controllo totale sulla memoria, sullâ€™IO, mentre user solamente gli indirizzi a lui illegali. Questo metodo permette di entrare in kernel mode in modo controllato, in modo che riesca sempre a gestire questa protezione.
    2. Ovviamente il cambio del mode bit Ã¨ privilegiato, un programma normalmente non puÃ² cambiare mode con una singola istruzione, deve passare con system call che sono le interrupt software o trap, con una istruzione specifica per mandare interrupt. Ãˆ l'unico modo!.
    3. Nota: ovviamente quando il computer parte, in **boostrap** Ã¨ in modalitÃ  kernel, che appena finisce tornerÃ  in User Mode (Ã¨ il processo INIT!)
2. Una mappatura a indirizzi illegali per il programma, in modo che possa accedere solamente a quello a cui dovrebbe accedere.

### Protezione memoria ðŸŸ©-

- Slide protezione Memoria MMU

    <img src="/images/notes/image/universita/ex-notion/Note sullâ€™architettura/Untitled 10.png" alt="image/universita/ex-notion/Note sullâ€™architettura/Untitled 10">


Questo pezzo di hardware ha il ruolo di **tradurre indirizzi logici in fisici**, e gestire l'accesso (ritorna lâ€™errore se non si potrebbe fare).

Ãˆimportante che sia in Hardware perchÃ©:

1. Deve essere molto veloce, perchÃ© sono operazioni molto veloci
2. Si potrebbe bypassare e allora avresti accesso a tutta la memoria ugualmente.

### System call ðŸŸ©-

La sistem call Ã¨ una unica istruzione, mediante la quale Ã¨ possibile accedere al kernel mode, in grado di accedere a tutto, utile per la protezione e affidabilitÃ  del sistema, e non permettere programmi di fare tutto.

Esistono convenzioni di chiamata, perchÃ© si aspetta in un certo registro la presenza di un codice che specifichi la tipologia di system call, poi la sistem call ritornerÃ  il valore corretto in un certo registro.