---
layout: page
permalink: notes/lâ€™intelligenza
tags: en
title: lâ€™intelligenza
---

Ripasso Prox: 30
Ultima modifica: January 26, 2023 10:03 PM
Primo Abbozzo: June 28, 2022 8:53 AM
Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•
Studi Personali: No

# Elementi di ripasso

August 22, 2022

# 1 Introduzione

Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.

Inoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla **universale**.

## 1.1 Lâ€™intelligenza artificiale

### 1.1.1 Cosa Ã¨ (2)

Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale. In generare si Ã¨ basato su alcuni parametri cardine ossia:

- La capacitÃ  di replicare attivitÃ  umane / la capacitÃ  di applicare attivitÃ  razionali
- La capacitÃ  di ragionare / il comportamento intelligente

Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso lâ€™intelligenza artificiale Ã¨ intelligente.

### 1.1.2 Modelli generali

Tra i modelli presenti quello di maggiore interesse nel tempo Ã¨ stato lâ€™ultimo, per il resto vanno a toccare molti campi che sono un pÃ² fuori dalle competenze dellâ€™informatico. (credo)

**Agire umanamente**

Come il test di turing, definisce lâ€™intelligenza artificiale come un software che riesce ad emulare il comportamento umano, talmente che non riusciresti a riconoscerlo.

Ma i ricercatori hanno preferito cercare di capire cosa Ã¨ lâ€™intelligenza in sÃ©, invece di cercare di emulare quella umana.

**Pensare umanamente**

Questo modello ha un campo molto fiorente nelle *scienze cognitive*, attraverso scan delle immagini, o comunque una conoscenza approfondita in primo luogo della stessa conoscenza umana, vogliamo cercare di costruire un intelligenza artificiale che ne emuli le capacitÃ  (pensiero interiore, psicologia etc).

**Pensare logico**

Questo Ã¨ stato uno dei primi metodi per costruire un software che si potesse considerare intelligente. Si basa sugli sviluppi della logica come campo di studi: ossia la possibilitÃ  di costruire software che siano in grado di dimostrare tutto il possibile.

Oppure utilizzando una analisi probabilistica, per analizzare la realtÃ .

**Agire logico**

Lâ€™immagine dellâ€™agente Ã¨ stato il metodo piÃ¹ florido nella storia dellâ€™intelligenza artificiale nel momento in cui se ne voleva costruire una. Tanto che lâ€™obiettivo della costruzione di un ente che potesse agire in modo logico in un ambiente si potrebbe considerare come se fosse un modello standard per la costruzione di un intelligenza artificiale.

Un problema perÃ² sorge: allineamento dei valori: a volte fare la cosa logicamente piÃ¹ corretta non Ã¨ la migliore soluzione, esempio se lâ€™obiettivo fosse vincere a tutti i costi una partita a scacchi, lâ€™agente, con la possibilitÃ  di agire sull'ambiente circostante, potrebbe compiere azioni che solitamente considereremmo ingiuste, al solo scopo di raggiungere questo obiettivo! â†’ vorremmo costruire qualche agente che sia in grado di portare un beneficio provato (dimostrato).

## 1.2 Lâ€™agente

Definiamo in modo molto generale, lâ€™agente come qualcosa che possiede **attuatori e percettori** per interagire e percepire lâ€™ambiente (che puÃ² essere molto vario).

Un concetto importante Ã¨ che lâ€™agente puÃ² basare il suo output attraverso solamente ciÃ² che ha percepito (dall'inizio fino al tempo corrente) quindi potremmo considerare lâ€™esistenza di una **funzione agente** che mappa sequenza input â†’ azione. e lâ€™implementazione di essa.

### 1.2.1 La razionalitÃ 

Vogliamo cercare di dare una definizione di razionalitÃ  in qualunque agente, e si puÃ² formalizzare in questo modo: **PEAS FRAMEWORK** (performance, env, actuators, sensors)

1. Una funzione di performance
2. Lâ€™insieme delle conoscenze a priori sul mondo
3. Lâ€™insieme delle azioni possibili sul mondo
4. La sequenza di percepimento

Con questi 4 oggetti, definiamo che lâ€™agente Ã¨ intelligente se la funzione che prende in input la sequenza di percezione e le conoscenze sul mondo, dia in output lâ€™azione che massimizza la performance.

**La misura della performance**

Il modo migliore che abbiamo per misurare la performance Ã¨ sulle conseguenze che ha sull'ambiente. Quindi valutare se lâ€™effetto che ha Ã¨ positivo (sempre in funzione alla positivitÃ  descritta da chi ha progettato lâ€™agente) o negativo.

Una nota: Ã¨ importante costruire la performance secondo gli effetti sull'ambiente, e non secondo il modo con cui si dovrebbe comportare lâ€™agente!

Ma non Ã¨ detto che sia il modo migliore per fare ciÃ², Ã¨ un problema piÃ¹ filosofico (quello sugli effetti uguali, ma uno sta basso e fa sempre, mentre lâ€™altro Ã¨ molto efficiente a momenti e per il resto del tempo sta proprio fermo).

**Onniscienza ed autonomia**

Non possiamo avere un agente che sappia tutto, bisogna tarare la performance su questa osservazione: lâ€™azione scelta non deve essere la migliore possibile in assoluto (altrimenti lâ€™agente dovrebbe sapere tutto) ma dovrebbe essere la migliore azione in guadagno atteso.

Questo comporta la migliore decisione che possa massimizzare scelte future (come *raccolta delle informazioni* si spende un pÃ² di tempo per raccogliere piÃ¹ informazioni sullâ€™ambiente) oppure lâ€™azione stessa nel caso si abbia giÃ  conoscenza sullâ€™ambiente.

Ãˆ da notare che il caso in cui si ha una totale conoscenza sullâ€™ambiente a priori (caso anche di alcune specie di animali come lowly dung beetle o sphex wasp) toglie di autonomia (ossia la capacitÃ  di agire a seconda di input ambientali e non solo secondo conoscenze a priori) allâ€™agente, e potrebbe non dare le soluzioni volute (in questi casi lâ€™agente agisce soltanto, perchÃ© pensa di sapere giÃ  tutto).

### 1.2.2 Lâ€™ambiente

Ci sono una moltitudine di variabili che possono risultare utili per classificare un ambiente tra cui:

1. Determinismo-nondeterminismo o stocastico
2. OsservabilitÃ  parziale-totale
3. singolo-multi agente
4. episodico - sequenziale (si basa o no su eventi passati?)
5. statico o dinamico (o semidinamico) (lâ€™ambiente puÃ² cambiare quando lâ€™agente pensa sul da farsi?)
6. discreto o continuo (gli stati sono infiniti o finiti?)
7. conosciuto o sconosciuto (i risultati delle azioni sono conosciute a priori, come se fossero leggi della fisica).

Per esempio, il progetto mnk-game Ã¨ un ambiente che Ã¨  Determinista, totalmente osservabile, agente multiplo, sequenziale, statico, discreto e conosciuto.

Questi direi sono i 7 cardini che definiscono ad alto livello un ambiente.

## 1.3 Tipologie di agente

In questa parte vengono descritti le tipologie di agente a cui si Ã¨ pensato. Parlando in generale Ã¨ come se fossero dei modelli che vengono costruiti uno sopra lâ€™altro, in senso crescente, fino ad arrivare allâ€™agente che apprende come modello finale (correntemente piÃ¹ gettonato).

I modelli qui presentati sono molto astratti, utili per semplicitÃ  e chiarezza, ma non ci aiuta in alcun modo per capire come implementare tale modello, tutti gli agenti qui presentati saranno di questo tipo

### 1.3.1 Basati su riflessi

Lâ€™agente che si basa sui riflessi Ã¨ il piÃ¹ semplice degli agenti che possono essere presenti. Come dice il nome si basa sul concetto di riflesso molto simile al riflesso umano, come sbattere le ciglia, scattare via da una fonte di calore simili azioni.

Si tratta di un agente che agisce sulla singola percezione e trova lâ€™azione corrispondente a seguito di questa. Le percezioni passate non interessano proprio, sa giÃ  agire subito dalla percezione presente.

**Caratteristiche di questo agente:**

- StaticitÃ  nelle azioni, esegue solo ciÃ² per cui Ã¨ programmato, quasi fosse un if-then agent, infatti dovremmo parlare di regole di condizione-azione
- NecessitÃ  di osservabilitÃ  totale, altrimenti Ã¨ difficile che faccia lâ€™azione piÃ¹ intelligente
- Modello in breve

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled">

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 1.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 1">


### 1.3.2 Basati su modelli

Questo modello si puÃ² considerare una espansione al modello precedente. Si cerca piano piano di rendere lâ€™agente piÃ¹ flessibile, e non soltanto qualcosa di programmato, come se fosse un singolo algoritmo:

Ora lâ€™agente possiede un modello interno del mondo, che Ã¨ cambiato a seconda della percezione nel momento. Quindi lâ€™azione ora non Ã¨ presa solamente secondo la percezione attuale, ma anche secondo il modello del mondo, e la percezione attuale.

**Caratteristiche**

1. Funzione di transizione del modello, che serve per aggiornare il modello interno del mondo a seconda dei cambiamenti percepiti
2. Funzione di sensore, che traduce le informazioni percepite in funzione dello stato del mondo (es. se ho la telecamera sporca di acqua per la pioggia, lâ€™input sarÃ  un pÃ² diverso)

Quindi maggiore flessibilitÃ  in confronto alla precedente.

- Modello in breve

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 2.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 2">

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 3.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 3">


### 1.3.3 Basati su obiettivi

Lâ€™ulteriore espansione di questo agente rispetto alla precedente Ã¨ che ora il modello tiene conto anche delle possibili conseguenze future delle proprie azioni in funzione del raggiungimento o meno del proprio obiettivo

**Caratteristiche**

1. Esistenza di un obiettivo ben dichiarato proprio (che condiziona la funzione di valutazione)
2. PossibilitÃ  di rimpiazzare lâ€™obiettivo precedente con uno simile (flessibilitÃ )
3. Aggiornamenti su conseguenze delle proprie azioni sullo stato del raggiungimento per lâ€™obiettivo
- Modello in breve

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 4.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 4">


### 1.3.4 Basati su utility

cerca di valutare se Ã¨ una conseguenza buona o cattiva, a seconda di una propria *funzione di valutazione* che cerchi di rispettare il meglio possibile la funzione di valutazione dellâ€™ambiente in cui Ã¨ presente.

Ãˆ buono in caso ci possano essere degli obiettivi che si eliminano uno a vicenda, Ã¨ buono per trovare i tradeoff **comune in molte situazioni (es. voglio arrivare piÃ¹ in fretta possibile, ma non voglio investire persone).

**Caratteristiche**

1. Una funzione di valutazione che cerca di *massimizzare il valore atteso della propria azione.*
- Modello in breve

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 5.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 5">


### 1.3.5 Basati su apprendimento

Al fine di avere un agente flessibile che possa adattarsi in ambienti anche molto differenti fra di loro, vorremmo creare un metodo per cui lâ€™agente possa imparare dai propri errori. Questo modello si prefissa lâ€™obiettivo di creare un framework generale per un agente che impara.

**Caratteristiche:**

1. Critico: cerca di valutare le azioni prese dallâ€™agente e pone consigli su cosa cambiare
2. Elemento apprendimento: che cambia lo *stato di conoscenza interna* dellâ€™agente in modo che possa prendere decisioni migliori, grazie al feedback del critico
3. generatore di problemi che propone nuovi problemi/esperimenti che possono migliorare altri tratti dellâ€™agente.
- Modello in breve

    Lâ€™agente vecchio Ã¨ interamente raccolto nel performance element

<img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 6.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 6">

    <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 6.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 6">


# 2 Registro ripassi

|  |  |
| --- | --- |
|  |  |
|  |  |
dello in breve